{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½¿ç”¨è®¾å¤‡: cpu\n",
      "============================================================\n",
      "è½¦ç‰Œæ£€æµ‹ä¸è¯†åˆ«ç³»ç»Ÿ - YOLOv8 è®­ç»ƒè„šæœ¬ (CPU ä¼˜åŒ–ç‰ˆ)\n",
      "============================================================\n",
      "ğŸ” éªŒè¯æ•°æ®é›†å®Œæ•´æ€§...\n",
      "è®­ç»ƒé›†: å›¾ç‰‡=5769, æ ‡ç­¾=5769, åŒ¹é…=5769\n",
      "âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼\n",
      "\n",
      "ğŸš€ å¼€å§‹è®­ç»ƒ YOLOv8 è½¦ç‰Œæ£€æµ‹æ¨¡å‹...\n",
      "New https://pypi.org/project/ultralytics/8.3.246 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.245  Python-3.9.19 torch-2.7.0+cpu CPU (Intel Core i7-10870H 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=0, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\\\Desktop\\\\BiYeSheJi\\CCPD2020\\CCPD2020\\CCPD2020_green_processed\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=plate_detection3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 642.5348.4 MB/s, size: 133.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ç™½ç‹\\Desktop\\æ–°å»ºæ–‡ä»¶å¤¹\\BiYeSheJi\\CCPD2020\\CCPD2020\\CCPD2020_green_processed\\train\\labels.cache... 5769 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5769/5769 11.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 824.2252.2 MB/s, size: 136.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ç™½ç‹\\Desktop\\æ–°å»ºæ–‡ä»¶å¤¹\\BiYeSheJi\\CCPD2020\\CCPD2020\\CCPD2020_green_processed\\val\\labels.cache... 1001 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1001/1001 1.2Mit/s 0.0s\n",
      "Plotting labels to C:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G     0.7809     0.8211     0.8887          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.7it/s 13:53<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 2.9it/s 43.1s0.4s\n",
      "                   all       1001       1001      0.992      0.986      0.994      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G     0.7236     0.4853     0.8755          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.7it/s 13:46<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.4s0.3s\n",
      "                   all       1001       1001       0.99      0.984      0.994      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G     0.6871     0.4337       0.87          1        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:05<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.6it/s 35.3s0.3s\n",
      "                   all       1001       1001      0.985      0.984      0.993      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G      0.671     0.4081     0.8698          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:24<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.5s0.3s\n",
      "                   all       1001       1001      0.995      0.991      0.995      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G     0.6419     0.3821     0.8634          4        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:37<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.5s0.3s\n",
      "                   all       1001       1001      0.994      0.987      0.995      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G     0.6242     0.3624     0.8562          1        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:29<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.1it/s 41.3s0.3s\n",
      "                   all       1001       1001      0.995      0.997      0.994      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G     0.5985     0.3394     0.8539          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:31<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.4s0.3s\n",
      "                   all       1001       1001      0.994      0.992      0.995      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.5888     0.3314     0.8498          1        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.4s0.3s\n",
      "                   all       1001       1001      0.982       0.99       0.99      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.5892     0.3237     0.8549          4        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.1it/s 41.1s0.3s\n",
      "                   all       1001       1001      0.985      0.989      0.993      0.822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.5747     0.3138     0.8535          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:25<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.1it/s 41.3s0.3s\n",
      "                   all       1001       1001      0.988      0.991      0.994      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.5555     0.2985     0.8482          1        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:24<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 42.5s0.3s\n",
      "                   all       1001       1001      0.997      0.995      0.994      0.849\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.5458     0.2847     0.8451          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:23<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.3s0.3s\n",
      "                   all       1001       1001      0.994      0.992      0.994      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.5326     0.2768     0.8417          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:26<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.1it/s 41.1s0.3s\n",
      "                   all       1001       1001      0.993      0.995      0.994       0.85\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.5187     0.2651     0.8425          0        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:30<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.5s0.3s\n",
      "                   all       1001       1001      0.993      0.992      0.994       0.85\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.5155     0.2563     0.8394          2        416: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1443/1443 1.8it/s 13:27<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.0it/s 41.7s0.3s\n",
      "                   all       1001       1001       0.99      0.994      0.994      0.861\n",
      "\n",
      "15 epochs completed in 3.543 hours.\n",
      "Optimizer stripped from C:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\\weights\\best.pt...\n",
      "Ultralytics 8.3.245  Python-3.9.19 torch-2.7.0+cpu CPU (Intel Core i7-10870H 2.20GHz)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 126/126 3.3it/s 38.6s0.3s\n",
      "                   all       1001       1001       0.99      0.994      0.994      0.861\n",
      "Speed: 0.7ms preprocess, 24.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\\\Desktop\\\\BiYeSheJi\\\\runs\\detect\\plate_detection3\u001b[0m\n",
      "âœ… YOLOv8 è®­ç»ƒå®Œæˆ!\n",
      "\n",
      "ğŸ‰ YOLOv8 è®­ç»ƒæˆåŠŸå®Œæˆï¼\n",
      "æ¨¡å‹ä¿å­˜ä½ç½®: runs/detect/plate_detection/weights/best.pt\n",
      "\n",
      "ğŸ’¡ åç»­æ­¥éª¤:\n",
      "1. ä½¿ç”¨è®­ç»ƒå¥½çš„ YOLOv8 æ¨¡å‹è£å‰ªç”Ÿæˆè½¦ç‰Œå›¾åƒæ•°æ®é›†\n",
      "2. ç”¨è£å‰ªåçš„å›¾åƒè®­ç»ƒ CRNN å­—ç¬¦è¯†åˆ«æ¨¡å‹\n",
      "3. é›†æˆä¸¤ä¸ªæ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ========== é…ç½®å‚æ•° ==========\n",
    "# æ˜ç¡®æŒ‡å®š CPUï¼ˆå› ä¸º GPU ä¸å¯ç”¨ï¼‰\n",
    "DEVICE = torch.device('cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {DEVICE}\")\n",
    "\n",
    "# è·¯å¾„é…ç½®\n",
    "BASE_PATH = r\"C:\\Users\\ç™½ç‹\\Desktop\\æ–°å»ºæ–‡ä»¶å¤¹\\BiYeSheJi\\CCPD2020\\CCPD2020\\CCPD2020_green_processed\"\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_PATH, \"train\", \"images\")  \n",
    "VAL_IMG_DIR = os.path.join(BASE_PATH, \"val\", \"images\")      \n",
    "\n",
    "def verify_dataset():\n",
    "    \"\"\"éªŒè¯æ•°æ®é›†æ˜¯å¦å®Œæ•´\"\"\"\n",
    "    print(\"ğŸ” éªŒè¯æ•°æ®é›†å®Œæ•´æ€§...\")\n",
    "    \n",
    "    # æ£€æŸ¥ images å’Œ labels æ˜¯å¦åŒ¹é…\n",
    "    train_img_dir = Path(TRAIN_IMG_DIR)\n",
    "    train_label_dir = Path(BASE_PATH) / \"train\" / \"labels\"\n",
    "    \n",
    "    if not train_img_dir.exists():\n",
    "        print(f\"âŒ è®­ç»ƒå›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {train_img_dir}\")\n",
    "        return False\n",
    "    \n",
    "    if not train_label_dir.exists():\n",
    "        print(f\"âŒ è®­ç»ƒæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {train_label_dir}\")\n",
    "        return False\n",
    "    \n",
    "    img_files = set(f.stem for f in train_img_dir.glob(\"*.jpg\"))\n",
    "    label_files = set(f.stem for f in train_label_dir.glob(\"*.txt\"))\n",
    "    \n",
    "    common_files = img_files & label_files\n",
    "    print(f\"è®­ç»ƒé›†: å›¾ç‰‡={len(img_files)}, æ ‡ç­¾={len(label_files)}, åŒ¹é…={len(common_files)}\")\n",
    "    \n",
    "    if len(common_files) == 0:\n",
    "        print(\"âŒ è­¦å‘Š: æ²¡æœ‰åŒ¹é…çš„å›¾ç‰‡å’Œæ ‡ç­¾æ–‡ä»¶ï¼\")\n",
    "        return False\n",
    "    \n",
    "    # éªŒè¯ç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "    sample_stem = next(iter(common_files))\n",
    "    sample_img = train_img_dir / f\"{sample_stem}.jpg\"\n",
    "    sample_label = train_label_dir / f\"{sample_stem}.txt\"\n",
    "    \n",
    "    # æ£€æŸ¥å›¾ç‰‡å¯è¯»å–ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰\n",
    "    img_array = np.fromfile(str(sample_img), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(f\"âŒ æ ·æœ¬å›¾ç‰‡æ— æ³•è¯»å–: {sample_img}\")\n",
    "        return False\n",
    "    \n",
    "    # æ£€æŸ¥æ ‡ç­¾æ ¼å¼\n",
    "    try:\n",
    "        with open(sample_label, 'r', encoding='utf-8') as f:\n",
    "            line = f.readline().strip()\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"âŒ æ ‡ç­¾æ ¼å¼é”™è¯¯: {sample_label}\")\n",
    "                return False\n",
    "            \n",
    "            cls_id = int(parts[0])\n",
    "            x, y, w, h = map(float, parts[1:])\n",
    "            \n",
    "            # éªŒè¯åæ ‡èŒƒå›´\n",
    "            if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                print(f\"âŒ æ ‡ç­¾åæ ‡è¶…å‡ºèŒƒå›´: {sample_label}\")\n",
    "                return False\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ ‡ç­¾è¯»å–é”™è¯¯ {sample_label}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ï¼\")\n",
    "    return True\n",
    "\n",
    "def train_yolo_detector():\n",
    "    \"\"\"è®­ç»ƒ YOLOv8 è½¦ç‰Œæ£€æµ‹æ¨¡å‹ï¼ˆCPU ä¼˜åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    print(\"\\nğŸš€ å¼€å§‹è®­ç»ƒ YOLOv8 è½¦ç‰Œæ£€æµ‹æ¨¡å‹...\")\n",
    "    \n",
    "    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (nano ç‰ˆæœ¬ï¼Œé€‚åˆç¬”è®°æœ¬)\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    # è®­ç»ƒé…ç½® (CPU å‹å¥½)\n",
    "    results = model.train(\n",
    "        data=os.path.join(BASE_PATH, 'data.yaml'),  # ä½¿ç”¨å®Œæ•´è·¯å¾„\n",
    "        epochs=15,             # é€‚å½“å‡å°‘è½®æ•°\n",
    "        batch=4,               # CPU å¿…é¡»å‡å° batch size\n",
    "        imgsz=416,             # é™ä½è¾“å…¥å°ºå¯¸ï¼ˆæ›´é€‚åˆç«–å±å›¾åƒï¼‰\n",
    "        patience=5,            # å†…ç½®æ—©åœ: 5è½®æ— æ”¹å–„åœæ­¢\n",
    "        device='cpu',          # æ˜ç¡®æŒ‡å®š CPU\n",
    "        close_mosaic=0,        # ç¦ç”¨ mosaic å¢å¼ºï¼ˆè§£å†³å¤§ç›®æ ‡é—®é¢˜ï¼‰\n",
    "        augment=False,         # ç¦ç”¨æ•°æ®å¢å¼ºï¼ˆCPU æ›´ç¨³å®šï¼‰\n",
    "        workers=2,             # å‡å°‘æ•°æ®åŠ è½½çº¿ç¨‹ï¼ˆé¿å… Windows é—®é¢˜ï¼‰\n",
    "        cache=False,           # ç¦ç”¨ç¼“å­˜ï¼ˆèŠ‚çœå†…å­˜ï¼‰\n",
    "        name='plate_detection' # ä¿å­˜ç›®å½•å\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… YOLOv8 è®­ç»ƒå®Œæˆ!\")\n",
    "    return model\n",
    "\n",
    "# ========== ä¸»å‡½æ•° ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"è½¦ç‰Œæ£€æµ‹ä¸è¯†åˆ«ç³»ç»Ÿ - YOLOv8 è®­ç»ƒè„šæœ¬ (CPU ä¼˜åŒ–ç‰ˆ)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # éªŒè¯æ•°æ®é›†\n",
    "    if not verify_dataset():\n",
    "        print(\"âŒ æ•°æ®é›†éªŒè¯å¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ\")\n",
    "        exit(1)\n",
    "    \n",
    "    # è®­ç»ƒ YOLOv8 æ£€æµ‹å™¨\n",
    "    try:\n",
    "        yolo_model = train_yolo_detector()\n",
    "        print(\"\\nğŸ‰ YOLOv8 è®­ç»ƒæˆåŠŸå®Œæˆï¼\")\n",
    "        print(f\"æ¨¡å‹ä¿å­˜ä½ç½®: runs/detect/plate_detection/weights/best.pt\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ YOLOv8 è®­ç»ƒå¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"\\nğŸ’¡ åç»­æ­¥éª¤:\")\n",
    "    print(\"1. ä½¿ç”¨è®­ç»ƒå¥½çš„ YOLOv8 æ¨¡å‹è£å‰ªç”Ÿæˆè½¦ç‰Œå›¾åƒæ•°æ®é›†\")\n",
    "    print(\"2. ç”¨è£å‰ªåçš„å›¾åƒè®­ç»ƒ CRNN å­—ç¬¦è¯†åˆ«æ¨¡å‹\")\n",
    "    print(\"3. é›†æˆä¸¤ä¸ªæ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
