"""è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿåç«¯æœåŠ¡ - æ”¯æŒé™æ€å›¾ç‰‡ + å®æ—¶è§†é¢‘ (FastAPI + YOLOv8 + CRNN)"""
import os
import io
import base64
import logging
from datetime import datetime
from typing import Optional, List, Dict
from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import cv2
import numpy as np
import torch
from PIL import Image
import ultralytics
from ultralytics import YOLO
import uuid
import asyncio
# ====== å®æ—¶è¯†åˆ«çŠ¶æ€ç®¡ç† ======
from collections import deque
import time

# å…¨å±€çŠ¶æ€ï¼ˆç®€å•åœºæ™¯å¯ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ç”¨ session æˆ– connection çº§çŠ¶æ€ï¼‰
live_state = {
    "recent_results": deque(maxlen=5),  # ç¼“å­˜æœ€è¿‘5å¸§ç»“æœ
    "last_valid_result": None,
    "last_seen_time": 0,
    "stable_plate": None,
    "stable_confidence": 0.0
}
# ======================
# é…ç½®ç®¡ç†
# ======================
class Settings:
    YOLO_MODEL_PATH = r"C:\Users\ç™½ç‹\Desktop\æ–°å»ºæ–‡ä»¶å¤¹\BiYeSheJi\æ¨¡å‹è®­ç»ƒ\runs\detect\plate_detection3\weights\best.pt"
    CRNN_MODEL_PATH = r"C:\BiYeSji\CRNN\crnn_best.pth"
    HOST = "0.0.0.0"
    PORT = 8000
    DEBUG = False
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    ALLOWED_EXTENSIONS = {".jpg", ".jpeg", ".png"}
    DB_URL = "mysql+pymysql://user:password@localhost/license_plate_db"
    REDIS_URL = "redis://localhost:6379/0"

settings = Settings()

# ======================
# å­—ç¬¦é›†å®šä¹‰
# ======================
PROVINCES = ['äº¬', 'æ²ª', 'æ´¥', 'æ¸', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘',
             'è‹', 'æµ™', 'çš–', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤',
             'æ¡‚', 'ç¼', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', 'é’', 'å®', 'æ–°',
             'æ¸¯', 'æ¾³', 'æŒ‚', 'å­¦', 'é¢†', 'ä½¿', 'ä¸´']
LETTERS = [chr(ord('A') + i) for i in range(26)]
DIGITS = [str(i) for i in range(10)]
CHARS = ['<blank>'] + PROVINCES + LETTERS + DIGITS
IDX2CHAR = {idx: ch for idx, ch in enumerate(CHARS)}

# ======================
# Pydanticæ¨¡å‹
# ======================
class RecognitionResult(BaseModel):
    success: bool
    plate_number: Optional[str] = None
    confidence: Optional[float] = None
    cropped_image: Optional[str] = None
    processing_time_ms: Optional[int] = None
    error_message: Optional[str] = None
    plate_type: Optional[str] = None
    timestamp: str = datetime.now().isoformat()

class PlateInfo(BaseModel):
    plate_number: str
    confidence: float
    bbox: List[int]
    plate_type: str
    timestamp: str

# ======================
# CRNNæ¨¡å‹å®šä¹‰
# ======================
class CRNN(torch.nn.Module):
    def __init__(self, num_classes, imgH=32, nc=1, nh=256):
        super(CRNN, self).__init__()
        assert imgH % 16 == 0, 'imgH must be a multiple of 16'
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(nc, 64, 3, 1, 1), torch.nn.ReLU(True), torch.nn.MaxPool2d(2, 2),
            torch.nn.Conv2d(64, 128, 3, 1, 1), torch.nn.ReLU(True), torch.nn.MaxPool2d(2, 2),
            torch.nn.Conv2d(128, 256, 3, 1, 1), torch.nn.BatchNorm2d(256), torch.nn.ReLU(True),
            torch.nn.Conv2d(256, 256, 3, 1, 1), torch.nn.ReLU(True), 
            torch.nn.MaxPool2d((2, 2), (2, 1), (0, 1)),
            torch.nn.Conv2d(256, 512, 3, 1, 1), torch.nn.BatchNorm2d(512), torch.nn.ReLU(True),
            torch.nn.Conv2d(512, 512, 3, 1, 1), torch.nn.ReLU(True), 
            torch.nn.MaxPool2d((2, 2), (2, 1), (0, 1)),
            torch.nn.Conv2d(512, 512, 2, 1, 0), torch.nn.ReLU(True)
        )
        self.rnn = torch.nn.LSTM(512, nh, num_layers=2, bidirectional=True, batch_first=True)
        self.fc = torch.nn.Linear(nh * 2, num_classes)
        
    def forward(self, x):
        conv = self.cnn(x)
        b, c, h, w = conv.size()
        assert h == 1, "the height of conv must be 1"
        rnn_input = conv.squeeze(2).permute(0, 2, 1)
        rnn_out, _ = self.rnn(rnn_input)
        output = self.fc(rnn_out)
        return output

# ======================
# è¾…åŠ©å‡½æ•° (å¿…é¡»åœ¨æ¨¡å‹åŠ è½½å‰å®šä¹‰)
# ======================
def predict_plate_type(plate_img):
    if len(plate_img.shape) == 2:
        plate_img = cv2.cvtColor(plate_img, cv2.COLOR_GRAY2BGR)
    
    mean_color = np.mean(plate_img, axis=(0, 1))
    b, g, r = mean_color
    total = r + g + b
    if total == 0:
        return "unknown"
    
    r_ratio = r / total
    g_ratio = g / total
    b_ratio = b / total
    
    if g_ratio > 0.35 and g_ratio > r_ratio and g_ratio > b_ratio:
        return "green"
    elif b_ratio > 0.25 and b_ratio > r_ratio:
        return "blue"
    elif r_ratio > 0.4 and g_ratio > 0.3:
        return "yellow"
    else:
        return "unknown"

def format_plate_number(plate_str, plate_type):
    if not plate_str or len(plate_str) < 5:
        return plate_str
    
    if plate_type == "green":
        if len(plate_str) >= 8:
            return plate_str[:2] + "Â·" + plate_str[2:]
        elif len(plate_str) == 7:
            return plate_str[:2] + "Â·" + plate_str[2:]
        else:
            return plate_str
    
    return plate_str[:7] if len(plate_str) > 7 else plate_str

def preprocess_for_crnn(image, img_height=32, img_width=280):
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    image = clahe.apply(image)
    
    image = cv2.resize(image, (img_width, img_height))
    image = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)
    image = image / 255.0
    image = (image - 0.5) / 0.5
    return image

def decode_ctc(outputs):
    _, preds = outputs.max(2)
    preds = preds.transpose(1, 0).cpu().numpy()
    decoded = []
    for seq in preds:
        out = []
        prev = -1
        for p in seq:
            if p != prev and p != 0:
                out.append(IDX2CHAR[p])
            prev = p
        plate_str = ''.join(out)
        decoded.append(plate_str)
    return decoded

# ======================
# åº”ç”¨åˆå§‹åŒ– (åªå®šä¹‰ä¸€æ¬¡!)
# ======================
app = FastAPI(
    title="æ™ºèƒ½è½¦ç‰Œè¯†åˆ«ç³»ç»ŸAPI",
    description="æ”¯æŒé™æ€å›¾ç‰‡ä¸Šä¼  + å®æ—¶è§†é¢‘æµè¯†åˆ«",
    version="1.1.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
yolo_model = None
crnn_model = None
task_queue: Dict[str, Dict] = {}

# ======================
# æ ¸å¿ƒè¯†åˆ«å‡½æ•°
# ======================
async def recognize_plate_from_image(img: np.ndarray, filename: str = "") -> dict:
    try:
        results = yolo_model(img, verbose=False)
        if len(results[0].boxes) == 0:
            return {"plate_number": "", "confidence": 0.0, "error": "æœªæ£€æµ‹åˆ°è½¦ç‰Œ"}

        boxes = results[0].boxes
        confidences = boxes.conf.cpu().numpy()
        best_idx = int(np.argmax(confidences))
        box = boxes.xyxy[best_idx].cpu().numpy().astype(int)
        confidence = float(confidences[best_idx])
        x1, y1, x2, y2 = box

        pad = max(5, int(min(x2-x1, y2-y1) * 0.1))
        x1 = max(0, x1 - pad)
        y1 = max(0, y1 - pad)
        x2 = min(img.shape[1], x2 + pad)
        y2 = min(img.shape[0], y2 + pad)
        plate_img = img[y1:y2, x1:x2]

        crnn_input = preprocess_for_crnn(plate_img).to(device)
        with torch.no_grad():
            crnn_output = crnn_model(crnn_input)
        plate_number_raw = decode_ctc(crnn_output.permute(1, 0, 2))[0]

        if not plate_number_raw or len(plate_number_raw) < 5:
            return {"plate_number": "", "confidence": confidence, "error": "å­—ç¬¦è¯†åˆ«å¤±è´¥"}

        plate_type = predict_plate_type(plate_img)
        plate_number = format_plate_number(plate_number_raw, plate_type)

        cropped_base64 = None
        if filename:
            _, buffer = cv2.imencode('.jpg', plate_img, [cv2.IMWRITE_JPEG_QUALITY, 85])
            b64 = base64.b64encode(buffer).decode('utf-8')
            cropped_base64 = f"data:image/jpeg;base64,{b64}"

        return {
            "plate_number": plate_number,
            "confidence": round(confidence, 4),
            "plate_type": plate_type,
            "cropped_image": cropped_base64,
            "file_name": filename
        }
    except Exception as e:
        return {"plate_number": "", "confidence": 0.0, "error": str(e)}

# ======================
# ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
# ======================
@app.on_event("startup")
async def load_models():
    global yolo_model, crnn_model
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        logger.info("æ­£åœ¨åŠ è½½YOLOè½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
        yolo_model = YOLO(settings.YOLO_MODEL_PATH)
        yolo_model.to(device)
        logger.info("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
    
    try:
        logger.info("æ­£åœ¨åŠ è½½CRNNå­—ç¬¦è¯†åˆ«æ¨¡å‹...")
        crnn_model = CRNN(num_classes=len(CHARS)).to(device)
        crnn_model.load_state_dict(
            torch.load(settings.CRNN_MODEL_PATH, map_location=device)
        )
        crnn_model.eval()
        logger.info("âœ… CRNNæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ CRNNæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise
    
    logger.info("æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
    dummy_img = np.zeros((32, 280, 3), dtype=np.uint8)
    _ = preprocess_for_crnn(dummy_img)
    logger.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")

@app.on_event("shutdown")
async def cleanup():
    global yolo_model, crnn_model
    del yolo_model
    del crnn_model
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")

# ======================
# APIç«¯ç‚¹
# ======================
@app.get("/healthz")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models_loaded": yolo_model is not None and crnn_model is not None,
        "device": str(device)
    }

@app.post("/api/v1/recognize", response_model=RecognitionResult)
async def recognize_plate(file: UploadFile = File(...)):
    start_time = datetime.now()
    
    # 1. éªŒè¯æ–‡ä»¶
    try:
        content = await file.read()
        if len(content) > settings.MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413, 
                detail=f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ{settings.MAX_FILE_SIZE/1024/1024}MB"
            )
        
        ext = os.path.splitext(file.filename)[1].lower()
        if ext not in settings.ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=415,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒ{', '.join(settings.ALLOWED_EXTENSIONS)}"
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
        return RecognitionResult(
            success=False,
            error_message=f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}",
            timestamp=datetime.now().isoformat()
        )
    
    # 2. è¯†åˆ«å¤„ç†
    try:
        nparr = np.frombuffer(content, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is None:
            raise ValueError("æ— æ³•è§£æå›¾åƒæ–‡ä»¶")
            
        result = await recognize_plate_from_image(img, file.filename)
        
        if "error" in result:
            return RecognitionResult(
                success=False,
                error_message=result["error"],
                timestamp=datetime.now().isoformat()
            )
        
        processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
        
        return RecognitionResult(
            success=True,
            plate_number=result["plate_number"],
            confidence=result["confidence"],
            cropped_image=result["cropped_image"],
            processing_time_ms=processing_time,
            plate_type=result["plate_type"],
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"è¯†åˆ«è¿‡ç¨‹å¼‚å¸¸: {e}")
        return RecognitionResult(
            success=False,
            error_message=f"è¯†åˆ«è¿‡ç¨‹å¼‚å¸¸: {str(e)}",
            timestamp=datetime.now().isoformat()
        )

# ======================
# WebSocket å®æ—¶è¯†åˆ«
# ======================
@app.websocket("/ws/live")
@app.websocket("/ws/live")
async def live_recognition(websocket: WebSocket):
    await websocket.accept()
    logger.info("ğŸŸ¢ å®æ—¶è¯†åˆ« WebSocket è¿æ¥å»ºç«‹")

    # ä¸ºæ¯ä¸ªè¿æ¥åˆ›å»ºç‹¬ç«‹çŠ¶æ€
    state = {
        "recent_results": deque(maxlen=5),      # ç”¨äºç¨³å®šæ€§æŠ•ç¥¨
        "last_seen_time": time.time(),
        "best_plate": None,                     # æœ€ä½³è½¦ç‰Œå·
        "best_confidence": 0.0,                 # æœ€ä½³ç½®ä¿¡åº¦
        "best_cropped_image": "",               # æœ€ä½³è£å‰ªå›¾ï¼ˆBase64ï¼‰
        "stable_plate": None,                   # å½“å‰ç¨³å®šè¾“å‡ºçš„è½¦ç‰Œ
    }

    try:
        while True:
            data = await websocket.receive_bytes()
            nparr = np.frombuffer(data, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                continue

            # ä½¿ç”¨æ ¸å¿ƒè¯†åˆ«å‡½æ•°
            result = await recognize_plate_from_image(img)
            current_time = time.time()

            plate_number = result.get("plate_number")
            confidence = result.get("confidence", 0.0)
            cropped_image = result.get("cropped_image", "")

            # === æ›´æ–°â€œæœ€ä½³è½¦ç‰Œâ€ç¼“å­˜ ===
            if plate_number and confidence > state["best_confidence"]:
                state["best_plate"] = plate_number
                state["best_confidence"] = confidence
                state["best_cropped_image"] = cropped_image
                logger.debug(f"ğŸ† æ›´æ–°æœ€ä½³è½¦ç‰Œ: {plate_number} (ç½®ä¿¡åº¦: {confidence:.2f})")

            # === ç¨³å®šæ€§æŠ•ç¥¨é€»è¾‘ï¼ˆåŒä¹‹å‰ï¼‰===
            if plate_number:
                state["recent_results"].append({
                    "plate": plate_number,
                    "confidence": confidence,
                    "timestamp": current_time
                })
                state["last_seen_time"] = current_time
            else:
                # è¶…æ—¶æ¸…ç©º recent_resultsï¼ˆä½†ä¿ç•™ bestï¼‰
                if current_time - state["last_seen_time"] > 3.0:
                    state["recent_results"].clear()

            # æŠ•ç¥¨å†³å®šå½“å‰ç¨³å®šè½¦ç‰Œ
            plate_votes = {}
            for r in state["recent_results"]:
                plate = r["plate"]
                plate_votes[plate] = plate_votes.get(plate, 0) + 1

            stable_plate = None
            for plate, votes in plate_votes.items():
                if votes >= 2:
                    stable_plate = plate
                    break

            state["stable_plate"] = stable_plate

            # === æ„å»ºå“åº”ï¼šä¼˜å…ˆä½¿ç”¨â€œæœ€ä½³â€è£å‰ªå›¾ ===
            final_plate = state["best_plate"] if state["best_plate"] else ""
            final_confidence = state["best_confidence"]
            final_cropped_image = state["best_cropped_image"]

            # å¦‚æœé•¿æ—¶é—´æœªè§è½¦ç‰Œï¼ˆæ¯”å¦‚5ç§’ï¼‰ï¼Œæ¸…ç©ºæœ€ä½³ç»“æœ
            if current_time - state["last_seen_time"] > 5.0:
                final_plate = ""
                final_cropped_image = ""
                final_confidence = 0.0

            response = {
                "success": bool(final_plate),
                "plate_number": final_plate,
                "plate_type": result.get("plate_type", "unknown"),
                "confidence": final_confidence,
                "cropped_image": final_cropped_image,
                "timestamp": datetime.now().isoformat()
            }

            await websocket.send_json(response)

    except Exception as e:
        logger.error(f"ğŸ”´ WebSocket é”™è¯¯: {e}")
    finally:
        await websocket.close()
        logger.info("ğŸ”´ å®æ—¶è¯†åˆ« WebSocket è¿æ¥å…³é—­")
# ======================
# æ‰¹é‡å¤„ç† (ä¿æŒåŸæœ‰åŠŸèƒ½)
# ======================
async def process_batch_task(task_id: str, files_data: List[dict]):
    try:
        task = task_queue.get(task_id)
        if not task:
            return
        
        results = []
        for file_data in files_data:
            nparr = np.frombuffer(file_data["content"], np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            result = await recognize_plate_from_image(img, file_data["filename"])
            results.append(result)
            task["processed_count"] += 1
            task["results"].append(result)
            await asyncio.sleep(0.1)
        
        task["status"] = "completed"
        task["end_time"] = datetime.now().isoformat()
        logger.info(f"æ‰¹é‡ä»»åŠ¡ {task_id} å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ‰¹é‡ä»»åŠ¡ {task_id} å¤„ç†å¤±è´¥: {e}")
        if task_id in task_queue:
            task_queue[task_id]["status"] = "failed"
            task_queue[task_id]["error"] = str(e)

@app.post("/api/v1/recognize-batch")
async def recognize_batch(files: List[UploadFile] = File(...), background_tasks: BackgroundTasks = None):
    # ... [æ‚¨çš„åŸæœ‰æ‰¹é‡å¤„ç†é€»è¾‘ï¼Œè°ƒç”¨ recognize_plate_from_image] ...
    try:
        if not files:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶")
        
        files_data = []
        for file in files:
            content = await file.read()
            if len(content) > settings.MAX_FILE_SIZE:
                raise HTTPException(status_code=413, detail=f"æ–‡ä»¶ {file.filename} è¿‡å¤§")
            ext = os.path.splitext(file.filename)[1].lower()
            if ext not in settings.ALLOWED_EXTENSIONS:
                raise HTTPException(status_code=415, detail=f"æ–‡ä»¶ {file.filename} ç±»å‹ä¸æ”¯æŒ")
            files_data.append({"content": content, "filename": file.filename})
        
        task_id = str(uuid.uuid4())
        task_queue[task_id] = {
            "status": "processing",
            "files_count": len(files_data),
            "processed_count": 0,
            "results": [],
            "start_time": datetime.now().isoformat()
        }
        
        background_tasks.add_task(process_batch_task, task_id, files_data)
        return {
            "success": True,
            "task_id": task_id,
            "message": f"æ‰¹é‡è¯†åˆ«ä»»åŠ¡å·²åˆ›å»ºï¼Œå…±{len(files_data)}å¼ å›¾ç‰‡",
            "timestamp": datetime.now().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡è¯†åˆ«å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/task/{task_id}")
async def get_task_status(task_id: str):
    task = task_queue.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {
        "task_id": task_id,
        "status": task["status"],
        "files_count": task["files_count"],
        "processed_count": task["processed_count"],
        "results": task["results"] if task["status"] == "completed" else [],
        "error": task.get("error"),
        "start_time": task["start_time"],
        "end_time": task.get("end_time")
    }

# ======================
# å¯åŠ¨åº”ç”¨
# ======================
if __name__ == "__main__":
    import uvicorn
    logger.info(f"ğŸš€ å¯åŠ¨è½¦ç‰Œè¯†åˆ«APIæœåŠ¡ (ç«¯å£: {settings.PORT})")
    logger.info(f"ğŸ“„ APIæ–‡æ¡£: http://localhost:{settings.PORT}/docs")
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        workers=1 if torch.cuda.is_available() else 4
    )